{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps to reproduce experiments in :\n",
    "## **Reproducible evaluation of methods for predicting progression to Alzheimerâ€™s disease from clinical and neuroimaging data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "The original [ADNI](http://adni.loni.usc.edu/) dataset should be downloaded without further touch (Data we used in our paper was downloaded in October 2016).\n",
    "Fix the paths where your data is stored on your computer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export ADNI_PATH=\"~/Aramis/Data/ADNI\"\n",
    "\n",
    "!export OUT_PATH=\"~/Aramis/Data/OUTPUT\"\n",
    "\n",
    "!export WORKING_DIR=\"~/Aramis/Data/tmp/WORKING_DIR\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Convert datasets into BIDS format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!clinica convert adni-to-bids $ADNI_PATH/IMAGES $ADNI_PATH/CLINICAL_DATA $OUT_PATH/ADNI/BIDS -m T1 PET_FDG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define folders for the next steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-5e0a6b7fedf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0madnimerge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'PATH/TO/ADNIMERGE.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0madni_bids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'OUT_PATH'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ADNI/BIDS'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0madni_tsv_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'OUT_PATH'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ADNI/TSV'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0madni_caps_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'OUT_PATH'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ADNI/CAPS'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/clinica_env2/lib/python3.6/posixpath.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(a, *p)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mdiscarded\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mAn\u001b[0m \u001b[0mempty\u001b[0m \u001b[0mlast\u001b[0m \u001b[0mpart\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpath\u001b[0m \u001b[0mthat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     ends with a separator.\"\"\"\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_sep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "adnimerge = 'PATH/TO/ADNIMERGE.csv'\n",
    "\n",
    "adni_bids = os.path.join(os.environ.get('OUT_PATH'), 'ADNI/BIDS')\n",
    "adni_tsv_dir = os.path.join(os.environ.get('OUT_PATH'), 'ADNI/TSV')\n",
    "adni_caps_dir = os.path.join(os.environ.get('OUT_PATH'), 'ADNI/CAPS')\n",
    "adni_output_dir = os.path.join(os.environ.get('OUT_PATH'), 'ADNI/OUTPUT')\n",
    "\n",
    "working_dir = os.environ.get('WORKING_DIR')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create the subjects lists\n",
    "Choose the subjects at baseline with available T1 MRI for ADNI, AIBL and OASIS, and with FDG-PET for ADNI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adni_bids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2e77ed065ba6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# For T1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0msubjects_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'T1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mrun_subjects_lists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madni_bids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madni_tsv_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatabase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubjects_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madnimerge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# For FDG-PET\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'adni_bids' is not defined"
     ]
    }
   ],
   "source": [
    "from Code.subjects_lists.subjects_lists import run_subjects_lists\n",
    "\n",
    "### ADNI dataset\n",
    "database = 'ADNI'\n",
    "\n",
    "# For T1\n",
    "subjects_list = 'T1'\n",
    "run_subjects_lists(adni_bids, adni_tsv_dir, database, subjects_list, adnimerge)\n",
    "\n",
    "# For FDG-PET\n",
    "subjects_list = 'PET'\n",
    "run_subjects_lists(adni_bids, adni_tsv_dir, database, subjects_list, adnimerge)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create demographic tables information\n",
    "Get demographic information of the different populations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adni_bids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c48a4c179140>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# For T1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0msubjects_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'T1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mrun_lists_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madni_bids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madni_tsv_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatabase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubjects_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madnimerge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# For FDG-PET\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'adni_bids' is not defined"
     ]
    }
   ],
   "source": [
    "from Code.subjects_lists.lists_stats import run_lists_stats\n",
    "\n",
    "### ADNI dataset\n",
    "database = 'ADNI'\n",
    "\n",
    "# For T1\n",
    "subjects_list = 'T1'\n",
    "run_lists_stats(adni_bids, adni_tsv_dir, database, subjects_list, adnimerge)\n",
    "\n",
    "# For FDG-PET\n",
    "subjects_list = 'PET'\n",
    "run_lists_stats(adni_bids, adni_tsv_dir, database, subjects_list, adnimerge)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run image processing pipelines\n",
    "Used pipelines are integrated into Clinica software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ADNI T1\n",
    "!clinica run t1-spm-full-prep $OUT_PATH/ADNI/BIDS $OUT_PATH/ADNI/CAPS/ ADNIbl -tsv /SUBJECTS_DIR/subjects_T1_PET.tsv -wd $WORKING_DIR -np 8\n",
    "### ADNI FDG-PET\n",
    "!clinica run pet-preprocess-volume $OUT_PATH/ADNI/BIDS $OUT_PATH/ADNI/CAPS/ ADNIbl -tsv $OUT_PATH/ADNI/TSV/subjects_T1_PET.tsv -wd $WORKING_DIR -np 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### AIBL and OASIS are registered into ADNI template to later test ADNI trained classifiers on AIBL and OASIS\n",
    "\n",
    "###AIBL\n",
    "!clinica run t1-spm-dartel-existing-template $OUT_PATH/AIBL/BIDS $OUT_PATH/AIBL/CAPS/ ADNIbl -tsv $OUT_PATH/AIBL/TSV/subjects_T1.tsv -wd $WORKING_DIR -np 8\n",
    "!clinica run t1-spm-dartel2mni $OUT_PATH/AIBL/BIDS $OUT_PATH/AIBL/CAPS/ AIBLbl -tsv $OUT_PATH/AIBL/TSV/subjects_T1.tsv -wd $WORKING_DIR -np 8\n",
    "\n",
    "###OASIS\n",
    "!clinica run t1-spm-dartel-existing-template $OUT_PATH/OASIS/BIDS $OUT_PATH/OASIS/CAPS/ ADNIbl -tsv $OUT_PATH/OASIS/SUBJECTS_DIR/subjects_T1.tsv -wd $WORKING_DIR -np 8\n",
    "!clinica run t1-spm-dartel2mni $OUT_PATH/OASIS/BIDS $OUT_PATH/OASIS/CAPS/ OASISbl -tsv $OUT_PATH/OASIS/SUBJECTS_DIR/subjects_T1.tsv -wd $WORKING_DIR -np 8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run the SVM classification tasks on imaging data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification results using T1-weighted MRI and FDG-PET images from ADNI dataset\n",
    "\n",
    "(from `experiments/0-imaging/svm_imaging.py`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import pandas as pd\n",
    "import clinica.pipeline.machine_learning.ml_workflows as ml_wf\n",
    "\n",
    "n_iterations = 250\n",
    "n_threads = 8\n",
    "\n",
    "group_id = 'ADNIbl'\n",
    "tasks = [('sMCI', 'pMCI'),\n",
    "         ('CN-', 'AD+')]\n",
    "image_types = ['T1', 'fdg']\n",
    "fwhm = 4\n",
    "pvc = None\n",
    "\n",
    "###################################\n",
    "### Voxel based classifications ###\n",
    "###################################\n",
    "             \n",
    "for task in tasks:\n",
    "    subjects_visits_tsv = path.join(adni_tsv_dir, '%s_vs_%s_subjects_sessions.tsv' % (task[0], task[1]))\n",
    "    diagnoses_tsv = path.join(adni_tsv_dir, '%s_vs_%s_diagnoses.tsv' % (task[0], task[1]))\n",
    "\n",
    "    for image_type in image_types:\n",
    "    \n",
    "        classification_dir = path.join(adni_output_dir, image_type, 'voxel_based', 'linear_svm',\n",
    "                                       '%s_vs_%s' % (task[0], task[1]))\n",
    "        if not path.exists(classification_dir):\n",
    "            os.makedirs(classification_dir)\n",
    "\n",
    "        print(\"Running %s\" % classification_dir)\n",
    "\n",
    "        wf = ml_wf.VB_RepHoldOut_DualSVM(adni_caps_dir, subjects_visits_tsv, diagnoses_tsv, group_id, image_type,\n",
    "                                         classification_dir, fwhm=fwhm, pvc=pvc, n_iterations=n_iterations,\n",
    "                                         n_threads=n_threads)\n",
    "        wf.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying SVM classifiers trained on CN-AB- vs AD-AB+ task to predict MCI progression\n",
    "\n",
    "(from `experiments/0-imaging/svm_predict_progression.py`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "import clinica.pipelines.machine_learning.svm_utils as utils\n",
    "\n",
    "import workflow\n",
    "\n",
    "spie_output_dir = path.join(adni_output_dir, 'SPIE')\n",
    "scores_dir = path.join(spie_output_dir, 'input_data', 'svm_scores')\n",
    "\n",
    "if not path.exists(scores_dir):\n",
    "            os.makedirs(scores_dir)\n",
    "\n",
    "group_id = 'ADNIbl'\n",
    "image_types = ['T1', 'fdg']\n",
    "\n",
    "tasks = [('sMCI', 'pMCI')]\n",
    "\n",
    "###################################\n",
    "### Voxel based classifications ###\n",
    "###################################\n",
    "\n",
    "for task in tasks:\n",
    "    subjects_visits_tsv = path.join(adni_tsv_dir, '%s_vs_%s_subjects_sessions.tsv' % (task[0], task[1]))\n",
    "    diagnoses_tsv = path.join(adni_tsv_dir, '%s_vs_%s_diagnoses.tsv' % (task[0], task[1]))\n",
    "\n",
    "    subjects_visits = pd.io.parsers.read_csv(subjects_visits_tsv, sep='\\t')\n",
    "    diagnoses_df = pd.io.parsers.read_csv(diagnoses_tsv, sep='\\t')\n",
    "    \n",
    "    for image_type in image_types:\n",
    "\n",
    "        svm_output_dir = path.join(adni_output_dir, image_type, 'voxel_based/linear_svm/CN-_vs_AD+/classifier')\n",
    "        input_images = workflow.VBAgeCorrectedInput(adni_caps_dir, subjects_visits_tsv, diagnoses_tsv, image_type, None)\n",
    "\n",
    "        x = input_images.get_x()\n",
    "        y = input_images.get_y()\n",
    "\n",
    "        w = np.loadtxt(path.join(svm_output_dir, 'weights.txt'))\n",
    "        b = np.loadtxt(path.join(svm_output_dir, 'intersect.txt'))\n",
    "\n",
    "        y_hat = np.dot(w, x.transpose()) + b\n",
    "        y_binary = (y_hat > 0) * 1.0\n",
    "        correct = (y == y_binary) * 1.0\n",
    "\n",
    "        print(utils.evaluate_prediction(y_binary, y))\n",
    "\n",
    "        results_df = pd.DataFrame({'participant_id': subjects_visits.participant_id.tolist(),\n",
    "                                   'session_id': subjects_visits.session_id.tolist(),\n",
    "                                   'diagnosis': diagnoses_df.diagnosis.tolist(),\n",
    "                                   'y': y.tolist(),\n",
    "                                   'y_binary': y_binary.tolist(),\n",
    "                                   'y_hat': y_hat,\n",
    "                                   'correct': correct})\n",
    "\n",
    "        results_df.to_csv(path.join(scores_dir, image_type + '.tsv'),\n",
    "                          index=False, sep='\\t', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Preparing data\n",
    "\n",
    "Data from different sources (clinical data from BIDS, including ADNIMERGE data, and SVM scores are joined into one file (`input_data.tsv`)\n",
    "(from `data_selection/join_input_data.py`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import path, environ\n",
    "\n",
    "\n",
    "adni_bids = path.join(environ.get('OUT_PATH'), 'ADNI/BIDS')\n",
    "adni_output_dir = path.join(environ.get('OUT_PATH'), 'ADNI/OUTPUT')\n",
    "spie_output_dir = path.join(adni_output_dir, 'SPIE')\n",
    "\n",
    "scores_dir = path.join(spie_output_dir, 'input_data/svm_scores')\n",
    "output_path = path.join(spie_output_dir, 'input_data')\n",
    "\n",
    "\n",
    "### Joining T1 and FDG-PET scores\n",
    "\n",
    "T1_df = pd.io.parsers.read_csv(path.join(scores_dir, 'T1.tsv'), sep='\\t')\n",
    "FDG_df = pd.io.parsers.read_csv(path.join(scores_dir, 'fdg.tsv'), sep='\\t')\n",
    "joined = T1_df.merge(FDG_df, on=['diagnosis', 'participant_id', 'session_id'])\n",
    "joined = joined.rename(columns={'y_hat_x': 'T1_score', 'y_hat_y': 'fdg_score'})\n",
    "subj_sessions = joined[['participant_id', 'session_id', 'diagnosis', 'T1_score', 'fdg_score']]\n",
    "\n",
    "participant_columns = [\"sex\", \"education_level\", \"marital_status\", \"apoe4\", \"apoe_gen1\", \"apoe_gen2\"]\n",
    "session_columns = [\"age\",\n",
    "                   # Cognitive measures\n",
    "                   \"MMSE\", \"cdr_sb\", \"cdr_global\", \"adas11\", \"adas13\",\n",
    "                   \"adas_memory\", \"adas_language\", \"adas_concentration\", \"adas_praxis\", \"ravlt_immediate\", \"moca\",\n",
    "                   \"TMT_A\", \"TMT_B\", \"dsst\", \"logmem_delay\", \"logmem_imm\",\n",
    "                   # T1 measures\n",
    "                   \"adni_ventricles_vol\", \"adni_hippocampus_vol\", \"adni_brain_vol\", \"adni_entorhinal_vol\",\n",
    "                   \"adni_fusiform_vol\", \"adni_midtemp_vol\", \"adni_icv\",\n",
    "                   # PET measures\n",
    "                   \"adni_fdg\", \"adni_pib\", \"adni_av45\",\n",
    "                   # CSF measures\n",
    "                   \"adni_abeta\", \"adni_tau\", \"adni_ptau\"]\n",
    "\n",
    "participant_series = {}\n",
    "session_series = {}\n",
    "for col in participant_columns:\n",
    "    participant_series[col] = []\n",
    "for col in session_columns:\n",
    "    session_series[col] = []\n",
    "\n",
    "participants_tsv = pd.io.parsers.read_csv(path.join(adni_bids, \"participants.tsv\"), sep='\\t')\n",
    "\n",
    "for row in subj_sessions.iterrows():\n",
    "    subj_sess = row[1]\n",
    "    selected_participant = participants_tsv[(participants_tsv.participant_id == subj_sess.participant_id)].iloc[0]\n",
    "    for col in participant_columns:\n",
    "        participant_series[col].append(selected_participant[col])\n",
    "\n",
    "    session_tsv = pd.io.parsers.read_csv(path.join(adni_bids, subj_sess.participant_id,\n",
    "                                                   subj_sess.participant_id + \"_sessions.tsv\"), sep='\\t')\n",
    "    selected_session = session_tsv[(session_tsv.session_id == subj_sess.session_id)].iloc[0]\n",
    "    for col in session_columns:\n",
    "        session_series[col].append(selected_session[col])\n",
    "\n",
    "for col in participant_columns:\n",
    "    subj_sessions.loc[:, col] = pd.Series(participant_series[col], index=subj_sessions.index)\n",
    "\n",
    "for col in session_columns:\n",
    "    subj_sessions.loc[:, col] = pd.Series(session_series[col], index=subj_sessions.index)\n",
    "\n",
    "subj_sessions.to_csv(path.join(output_path, 'input_data.tsv'), sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating different data tables\n",
    "\n",
    "For each of the the different populations determined by data availability, a separated data input file is created and splits for cross-validation are generated.\n",
    "(from `data_selection/generate_input_data.py`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path, environ\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from workflow import TsvInput\n",
    "\n",
    "\n",
    "adni_output_dir = path.join(environ.get('OUT_PATH'), 'ADNI/OUTPUT')\n",
    "spie_output_dir = path.join(adni_output_dir, 'SPIE')\n",
    "\n",
    "input_data_path = path.join(spie_output_dir, 'input_data')\n",
    "tasks_data_path = path.join(spie_output_dir, 'tasks_lists')\n",
    "\n",
    "subj_sessions = pd.io.parsers.read_csv(path.join(input_data_path, 'input_data.tsv'), sep='\\t')\n",
    "\n",
    "subj_sessions.loc[subj_sessions[subj_sessions.sex == 'F'].index, 'sex'] = 1\n",
    "subj_sessions.loc[subj_sessions[subj_sessions.sex == 'M'].index, 'sex'] = 0\n",
    "\n",
    "\n",
    "##################################################\n",
    "### Table 1 - Clinical data and Imaging scores ###\n",
    "##################################################\n",
    "\n",
    "model_36 = subj_sessions[~subj_sessions.adas13.isnull()]\n",
    "model_36.to_csv(path.join(input_data_path, 'table_1_clinical_imaging', 'input_data_model_36.tsv'), sep='\\t', index=False)\n",
    "\n",
    "\n",
    "####################################################\n",
    "### Table 2 - Clinical data and ADNIMERGE scores ###\n",
    "####################################################\n",
    "\n",
    "model_36 = subj_sessions[~subj_sessions.adas13.isnull() &\n",
    "                         ~subj_sessions.adni_ventricles_vol.isnull() &\n",
    "                         ~subj_sessions.adni_hippocampus_vol.isnull() &\n",
    "                         ~subj_sessions.adni_brain_vol.isnull() &\n",
    "                         ~subj_sessions.adni_entorhinal_vol.isnull() &\n",
    "                         ~subj_sessions.adni_icv.isnull() &\n",
    "                         ~subj_sessions.adni_fusiform_vol.isnull() &\n",
    "                         ~subj_sessions.adni_midtemp_vol.isnull()]\n",
    "\n",
    "model_36[\"adni_ventricles_vol_icv\"] = model_36.adni_ventricles_vol / model_36.adni_icv\n",
    "model_36[\"adni_hippocampus_vol_icv\"] = model_36.adni_hippocampus_vol / model_36.adni_icv\n",
    "model_36[\"adni_brain_vol_icv\"] = model_36.adni_brain_vol / model_36.adni_icv\n",
    "model_36[\"adni_entorhinal_vol_icv\"] = model_36.adni_entorhinal_vol / model_36.adni_icv\n",
    "model_36[\"adni_fusiform_vol_icv\"] = model_36.adni_fusiform_vol / model_36.adni_icv\n",
    "model_36[\"adni_midtemp_vol_icv\"] = model_36.adni_midtemp_vol / model_36.adni_icv\n",
    "\n",
    "model_36.to_csv(path.join(input_data_path, 'table_2_clinical_adnimerge', 'input_data_model_36.tsv'), sep='\\t', index=False)\n",
    "\n",
    "\n",
    "######################################################\n",
    "### Table 3 - Clinical data and Amyloid deposition ###\n",
    "######################################################\n",
    "\n",
    "model_36 = subj_sessions[~subj_sessions.adas13.isnull() &\n",
    "                         (~subj_sessions.adni_pib.isnull() |\n",
    "                          ~subj_sessions.adni_av45.isnull())]\n",
    "\n",
    "model_36[\"amyloid\"] = ((model_36.adni_pib >= 1.47) * 1.0) + ((model_36.adni_av45 >= 1.1) * 1.0)\n",
    "\n",
    "model_36.to_csv(path.join(input_data_path, 'table_3_amyloid', 'input_data_model_36.tsv'), sep='\\t', index=False)\n",
    "\n",
    "\n",
    "####################################\n",
    "### Table 4 - Several timepoints ###\n",
    "####################################\n",
    "\n",
    "model_36 = subj_sessions[~subj_sessions.adas13.isnull()]\n",
    "\n",
    "for i in range(1, 7):\n",
    "\n",
    "    model = []\n",
    "    diagnoses = pd.io.parsers.read_csv(path.join(tasks_data_path, 'sMCI_vs_pMCI_diagnoses_%s.tsv' % (i * 6)), sep='\\t')\n",
    "\n",
    "    for row in diagnoses.iterrows():\n",
    "        subj = row[1]\n",
    "        data_subj = model_36[model_36.participant_id == subj.participant_id]\n",
    "        if data_subj.shape[0] == 1:\n",
    "            data_subj.diagnosis = 0\n",
    "            data_subj.diagnosis = subj.diagnosis\n",
    "            model.append(data_subj)\n",
    "\n",
    "    model_t = pd.concat(model)\n",
    "    model_t.to_csv(path.join(input_data_path, 'table_4_timepoints', 'input_data_model_%s.tsv' % (i * 6)), sep='\\t', index=False)\n",
    "\n",
    "\n",
    "########################################\n",
    "### Generating splits for each table ###\n",
    "########################################\n",
    "\n",
    "n_iterations = 250\n",
    "test_size = 0.2\n",
    "\n",
    "tables_timepoints = {'table_1_clinical_imaging': [36],\n",
    "                     'table_2_clinical_adnimerge': [36],\n",
    "                     'table_3_amyloid': [36],\n",
    "                     'table_4_timepoints': [6, 12, 18, 24, 30, 36]}\n",
    "\n",
    "for table in tables_timepoints:\n",
    "    for timepoint in tables_timepoints[table]:\n",
    "\n",
    "        data_tsv = path.join(input_data_path, table, 'input_data_model_%s.tsv' % timepoint)\n",
    "        input_data = TsvInput(data_tsv)\n",
    "        y = input_data.get_y()\n",
    "\n",
    "        splits = StratifiedShuffleSplit(n_splits=n_iterations, test_size=test_size)\n",
    "        splits_indices = list(splits.split(np.zeros(len(y)), y))\n",
    "\n",
    "        with open(path.join(input_data_path, table, 'indices_model_%s.tsv' % timepoint), 'wb') as s:\n",
    "            pickle.dump(splits_indices, s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Experiments using demographic, clinical data, and imaging scores\n",
    "\n",
    "(from `experiments/1_clinical_imaging/rf_clinical_imaging.py`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import inspect\n",
    "\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0, parentdir)\n",
    "\n",
    "from general_models import rf_classifications\n",
    "\n",
    "# Paths to personalize\n",
    "spie_output_dir = os.path.join(os.environ.get('OUT_PATH'), 'ADNI/OUTPUT', 'SPIE')\n",
    "\n",
    "input_data_path = os.path.join(spie_output_dir, 'input_data', 'table_1_clinical_imaging')\n",
    "data_tsv_template = input_data_path + \"/input_data_model_%s.tsv\"\n",
    "indices_template = input_data_path + \"/indices_model_%s.pkl\"\n",
    "output_dir = os.path.join(spie_output_dir, 'output_data', '1_clinical_imaging')\n",
    "\n",
    "n_threads = 8\n",
    "months = [36]\n",
    "\n",
    "models = {\n",
    "\n",
    "          # Models using only demographic and clinical data\n",
    "\n",
    "          \"base\": [\"sex\", \"education_level\", \"MMSE\", \"cdr_sb\"],\n",
    "\n",
    "          \"base_logmem\": [\"sex\", \"education_level\", \"MMSE\", \"cdr_sb\", \"logmem_delay\", \"logmem_imm\"],\n",
    "\n",
    "          \"base_ravlt\": [\"sex\", \"education_level\", \"MMSE\", \"cdr_sb\", \"ravlt_immediate\"],\n",
    "\n",
    "          \"base_logmem_ravlt\": [\"sex\", \"education_level\", \"MMSE\", \"cdr_sb\", \"ravlt_immediate\", \"logmem_delay\",\n",
    "                                \"logmem_imm\"],\n",
    "\n",
    "          \"base_adas\": [\"sex\", \"education_level\", \"MMSE\", \"cdr_sb\", \"adas_memory\", \"adas_language\",\n",
    "                              \"adas_concentration\", \"adas_praxis\"],\n",
    "\n",
    "          \"base_ravlt_adas\": [\"sex\", \"education_level\", \"MMSE\", \"cdr_sb\", \"adas_memory\", \"adas_language\",\n",
    "                              \"adas_concentration\", \"adas_praxis\", \"ravlt_immediate\"],\n",
    "\n",
    "          # Models including APOE\n",
    "\n",
    "          \"base_ravlt_apoe\": [\"sex\", \"education_level\", \"apoe4\", \"MMSE\", \"cdr_sb\", \"ravlt_immediate\"],\n",
    "\n",
    "          \"base_adas_apoe\": [\"sex\", \"education_level\", \"apoe4\", \"MMSE\", \"cdr_sb\", \"adas_memory\", \"adas_language\",\n",
    "                             \"adas_concentration\", \"adas_praxis\"],\n",
    "\n",
    "          \"base_ravlt_adas_apoe\": [\"sex\", \"education_level\", \"apoe4\", \"MMSE\", \"cdr_sb\", \"adas_memory\", \"adas_language\",\n",
    "                                   \"adas_concentration\", \"adas_praxis\", \"ravlt_immediate\"],\n",
    "\n",
    "          # Models including imaging scores\n",
    "\n",
    "          \"base_T1score\": [\"sex\", \"education_level\", \"MMSE\", \"cdr_sb\", \"T1_score\"],\n",
    "\n",
    "          \"base_fdgscore\": [\"sex\", \"education_level\", \"MMSE\", \"cdr_sb\", \"fdg_score\"],\n",
    "\n",
    "          \"base_scores\": [\"sex\", \"education_level\", \"MMSE\", \"cdr_sb\", \"T1_score\", \"fdg_score\"],\n",
    "\n",
    "          \"base_ravlt_scores\": [\"sex\", \"education_level\", \"MMSE\", \"cdr_sb\", \"ravlt_immediate\", \"T1_score\", \"fdg_score\"],\n",
    "\n",
    "          \"base_adas_scores\": [\"sex\", \"education_level\", \"MMSE\", \"cdr_sb\", \"adas_memory\", \"adas_language\",\n",
    "                               \"adas_concentration\", \"adas_praxis\", \"T1_score\", \"fdg_score\"],\n",
    "\n",
    "          \"base_adas_memtest_scores\": [\"sex\", \"education_level\", \"MMSE\", \"cdr_sb\", \"adas_memory\", \"adas_language\",\n",
    "                                       \"adas_concentration\", \"adas_praxis\", \"ravlt_immediate\", \"T1_score\", \"fdg_score\"]\n",
    "\n",
    "}\n",
    "\n",
    "for model_name in models:\n",
    "    rf_classifications(model_name, models[model_name], data_tsv_template, indices_template, output_dir, months,\n",
    "                       n_threads=n_threads)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other experiments\n",
    "\n",
    "Other classification tasks can be run directly from the `experiments` directory:\n",
    "\n",
    "####  Using demographic, clinical data, and imaging data from ADNIMERGE file\n",
    "\n",
    "```\n",
    "python experiments/2_clinical_adnimerge/rf_clinical_adnimerge.py\n",
    "```\n",
    "\n",
    "####  Taking subjects amyloid status into account\n",
    "\n",
    "```\n",
    "python experiments/3_amyloid/rf_amyloid.py\n",
    "```\n",
    "\n",
    "#### Predicting progression at different time-points\n",
    "\n",
    "```\n",
    "python experiments/3_amyloid/rf_amyloid.py\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
